\documentclass[11pt]{report}
\input{preamble}
\begin{document}
\thispagestyle{empty}
{\LARGE \bf ECE 253 Lecture Notes}\\
{\large Hei Shing Cheung}\\
Digital and Computer Systems, Fall 2025 \hfill ECE253\\
\\
The up-to-date version of this document can be found at \url{https://github.com/HaysonC/skulenotes}\\

\chapter{Digital Circuits that Compute, Store, and Control}
\begin{shaded}
\section*{Introduction}
\paragraph{Layers of Computation} In hardware, we have the following layers of abstraction:
\begin{itemize}
    \item Computation
    \item Adders 
    \item Logic Gates
    \item Transistors
    \item Silicon
\end{itemize}
In this course, we will focus on the first three layers, on top of the logic gate level.


\paragraph{Layer of abstraction} At this course, for the digital systems part, we would start from understanding logic gates, all the way to understanding computer architecture, with each level of abstraction hiding the details of the lower level.

\section{Hierarchy, Modularity, and Regularity}

\begin{definition}[Hierarchy]
    The division of system into a set of modules, then further subdividing each module into smaller modules, and so on, until pieces are \textit{easy} to understand.    
\end{definition}

\begin{definition}[Modularity]
    The design principle that modules have well-defined functions and interfaces so they connect easily without unintended side effects.
\end{definition}

\begin{definition}[Regularity]
    The uniformality of modules, such that the reusability of common modules reduces the number of distinct modules to be designed.
\end{definition}

\subsection{Digital Logic Gates}
Logic gates are made out of transistors:
\begin{definition}[Transistor]
    A transistor is a 3-terminal device behaving as a switch. When the voltage on the terminal is HI, the switch is closed, and when the voltage is LO, the switch is open.
\end{definition}

\paragraph{Factors Affecting Speed of Digital Circuits}
\begin{itemize}
    \item \textbf{Transistors and Electrons take time to switch.} A transistor (State of the Art) takes 2-3 picoseconds to switch. Gates takes 40 ps and an 8-bit adder takes 300 ps.
    \item \textbf{Wires take time to propagate signals.} Signals travel at approximately 2/3 the speed of light in a vacuum, which is about 200,000 kilometers per second in a typical silicon wire.
    \item \textbf{Capacitance} There would be RCL circuits formed by the wires and transistors, which would cause delay.
\end{itemize}

\end{shaded}

% ===================== PART A: DIGITAL LOGIC FOUNDATIONS =====================
\section{Digital Logic Foundations}
% Representation and arithmetic first, then devices and gates, then algebra/minimization
% --- Representation ---
\subsection{Number Systems}
\begin{definition}[Number System]
    A number system is a way of representing numbers using a set of symbols (digits) and a base (radix). The base determines the number of unique digits that can be used in the number system.
\end{definition}

\paragraph{Common Number Systems} You should be familiar with the following number systems:
\begin{itemize}
    \item Decimal (Base 10): Digits 0-9
    \item Binary (Base 2): Digits 0-1
    \item Hexadecimal (Base 16): Digits 0-9, A-F
\end{itemize}

In computer systems, we use binary to represent information, and we would often use hexadecimal to represent binary numbers in a more compact way - a group of 4 bits (a nibble) can be represented by a single hexadecimal digit.

\begin{example}[Binary, Decimal, and Hexadecimal Numbers]
    Below is a table showing the conversion of binary numbers to decimal numbers, along with their hexadecimal representation.
    \begin{table}[h!]
        \centering
        \begin{tabular}{|c|c|c|}
            \hline
            Binary & Decimal & Hexadecimal \\
            \hline
            0000 & 0 & 0 \\
            0001 & 1 & 1 \\
            0010 & 2 & 2 \\
            0011 & 3 & 3 \\
            0100 & 4 & 4 \\
            0101 & 5 & 5 \\
            0110 & 6 & 6 \\
            0111 & 7 & 7 \\
            1000 & 8 & 8 \\
            1001 & 9 & 9 \\
            1010 & 10 & A \\
            1011 & 11 & B \\
            1100 & 12 & C \\
            1101 & 13 & D \\
            1110 & 14 & E \\
            1111 & 15 & F \\
            \hline
        \end{tabular}
        \caption{Binary to Decimal and Hexadecimal Conversion}
    \end{table}
    
\end{example}
\begin{example}[Decimal to Binary Conversion]
    To convert a decimal number to binary, we can use the method of successive division by 2. For example, to convert the decimal number 437 to binary:
    \begin{align*}
        437 \div 2 &= 218 & \text{remainder 1} \\
        218 \div 2 &= 109 & \text{remainder 0} \\
        109 \div 2 &= 54 & \text{remainder 1} \\
        54 \div 2 &= 27 & \text{remainder 0} \\
        27 \div 2 &= 13 & \text{remainder 1} \\
        13 \div 2 &= 6 & \text{remainder 1} \\
        6 \div 2 &= 3 & \text{remainder 0} \\
        3 \div 2 &= 1 & \text{remainder 1} \\
        1 \div 2 &= 0 & \text{remainder 1}
    \end{align*}
    Reading the remainders from bottom to top, we get the binary representation of 437
\end{example}

\begin{example}
    To convert (512000)$_{10}$ to binary, we recognize that $512000 = 2^9 \times 1000$. We know that $2^9 = 512$ and $1000_{10} = 1111101000_2$ (by method outlined above). Therefore, we can shift the binary representation of 1000 left by 9 bits to get the binary representation of 512000:
    \[(512000)_{10} = (1111101000000000000)_2\]
\end{example}

\paragraph{Note} An alternative method is to devide by powers of 2.
\begin{shaded}
    \textbf{Fractional Numbers. } To represent fractional numbers in binary, we can use the method of successive multiplication by 2 (fixed point representation). Or we can use floating point representation, which is similar to scientific notation in decimal. 
\end{shaded}
\subsection{Binary Arithmetic and Logic}
\paragraph{Binary Arithmetic} Binary arithmetic is similar to decimal arithmetic, but it only uses two digits (0 and 1). Addition is associated with a sum and carry.

\paragraph{Binary Addition} The rules for binary addition are as follows: \\
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        A & B & Sum, Carry \\
        \hline
        0 & 0 & 0, 0 \\
        0 & 1 & 1, 0 \\
        1 & 0 & 1, 0 \\
        1 & 1 & 0, 1 \\
        \hline
    \end{tabular}
    \caption{Binary Addition}
\end{table}

This could be summerize as the following logic:
\begin{equation}
    \text{Sum} = A \oplus B, \quad \text{Carry} = A \cdot B
\end{equation}
\paragraph{Binary Subtraction} The rules for binary subtraction are defined using the addition of negative numbers (2's complement):

\begin{definition}[Least Significant Bit (LSB) and Most Significant Bit (MSB)]
    The least significant bit (LSB) is the rightmost bit in a binary number, while the most significant bit (MSB) is the leftmost bit.`'
    
\end{definition}
\begin{definition}[2's Complement]
    The 2's complement of a binary number is obtained by inverting all the bits (1's complement) and adding 1 to the least significant bit (LSB).
\end{definition}

\begin{example}[Number Inversion]
    To find the 2's complement of the binary number (10110010)$_2$:
    \begin{enumerate}
        \item Invert all the bits: (01001101)$_2$
        \item Add 1 to the LSB: 
        \[
        \begin{array}{c}
        \quad 01001101 \\
        +\, 00000001 \\
        \hline
        \quad 01001110 \\
        \end{array}
        \]
    \end{enumerate}
    Therefore, the 2's complement of (10110010)$_2$ is (01001110)$_2$.
\end{example}

\begin{definition}[Logic Function]
    A logic function $L: \{0,1\}^n \rightarrow \{0,1\}$ is a mathematical function that takes $n$ binary inputs and produces a single binary output based on a set of rules.
\end{definition}

\begin{definition}[Truth Table]
    A truth table is a tabular representation of a logic function that lists all possible combinations of input values and their corresponding output values.
    
\end{definition}

\begin{definition}[Boolean Algebra]
    Boolean algebra is a branch of algebra that deals with binary variables and logical operations. It provides a set of rules and properties for manipulating and simplifying logic functions. The specific rules and properties would be covered in later lectures.
\end{definition}
% --- Devices and gates ---
\subsection{Transistors as Switches}
\begin{definition}[Transistor]
    Transistor operates as a switch. The switch is open only when the gate is high. We denote the state of the gate as $x \in \{0,1\}$, where 0 is LO and 1 is HI. If input end of the switch is HI, the output end could be modeled by the logic function:
    $$
        L(x) = x
    $$
\end{definition}

\begin{example}[Serial Transistors]
    Consider two transistors connected in series, with the input end of the first transistor connected to HI. The output end of the second transistor can be modeled by the following truth table:
    \begin{table}[h!]
        \centering
        \begin{tabular}{|c|c|c|}
            \hline
            $x_1$ & $x_2$ & $L(x_1, x_2)$ \\
            \hline
            0 & 0 & 0 \\
            0 & 1 & 0 \\
            1 & 0 & 0 \\
            1 & 1 & 1 \\
            \hline
        \end{tabular}
        \caption{Truth Table for Two Transistors in Series}
        \label{tab:and_gate}
    \end{table}
    \\
    The logic function can be expressed as:
    $$
        L(x_1, x_2) = x_1 \cdot x_2
    $$
    where $\cdot$ denotes the AND operation.
\end{example}

\begin{example}[Parallel Transistors]
    Consider two transistors connected in parallel, with the input end of both transistors connected to HI. The output end can be modeled by the following truth table:
    \begin{table}[h!]
        \centering
        \begin{tabular}{|c|c|c|}
            \hline
            $x_1$ & $x_2$ & $L(x_1, x_2)$ \\
            \hline  
            0 & 0 & 0 \\
            0 & 1 & 1 \\
            1 & 0 & 1 \\
            1 & 1 & 1 \\
            \hline
        \end{tabular}
        \caption{Truth Table for Two Transistors in Parallel}
        \label{tab:or_gate}
    \end{table}
    \\
    The logic function can be expressed as:
    $$
        L(x_1, x_2) = x_1 + x_2
    $$
    where $+$ denotes the OR operation.
\end{example}

\begin{example}
    Consider a circuit with a transistor connected to LO and the output end connected to LO, The other ends of the output and the transistor are connected together to a HI (and a resistor). The output end of the circuit can be modeled by the following truth table:
    \begin{table}[h!]
        \centering
        \begin{tabular}{|c|c|}
            \hline
            $x$ & $L(x)$ \\
            \hline
            0 & 1 \\
            1 & 0 \\
            \hline
        \end{tabular}
        \caption{Truth Table for a Transistor Connected to LO}
        \label{tab:not_gate}
    \end{table}
    \\
    The logic function can be expressed as:
    $$
        L(x) = \overline{x}
    $$
    where $\overline{x}$ denotes the NOT operation.
\end{example}

\subsection{Basic Logic Gates}

\begin{definition}[AND Gate]
    An AND gate outputs 1 only if all inputs are 1. The truth table for a 2-input AND gate is shown in Table \ref{tab:and_gate}.
    \\
    The logic function for an AND gate with inputs $A$ and $B$ can be expressed as:
    $$
        L(A, B) = A \cdot B = AB 
    $$
    \textbf{Note} when no operator is present, it is assumed to be AND.

    The digital logic symbol for an AND gate is shown below:
    \begin{center}
        \begin{tikzpicture}[scale=1]
            % Simple custom AND gate to avoid reliance on gate shape anchors
            % Input nodes
            \node (A) at (-1,0.3) {$A$};
            \node (B) at (-1,-0.3) {$B$};
            % Wires to gate
            \draw (A.east) -- (-0.2,0.3);
            \draw (B.east) -- (-0.2,-0.3);
            % Gate body: rectangle on the left and semicircle on the right
            \draw (-0.2,0.6) -- (-0.2,-0.6) -- (0.2,-0.6) arc (-90:90:0.6) -- cycle;
            % Output
            \node (Y) at (0.9,0) {$Y$};
            \draw (0.6,0) -- (Y.west);
            \draw (0.2,0) -- (0.6,0);
        \end{tikzpicture}
    \end{center}    
\end{definition}

\begin{definition}[OR Gate]
    An OR gate outputs 1 if at least one input is 1. The truth table for a 2-input OR gate is shown in Table \ref{tab:or_gate}.
    \\
    The logic function for an OR gate with inputs $A$ and $B$ can be expressed as:
    $$
        L(A, B) = A + B
    $$
    The digital logic symbol for an OR gate is shown below:
    \begin{center}
        \begin{tikzpicture}[scale=1]
            % Simple custom OR gate to avoid reliance on gate shape anchors
            % Input nodes
            \node (A) at (-1,0.3) {$A$};
            \node (B) at (-1,-0.3) {$B$};
            % Wires to gate
            \draw (A.east) -- (-0.2,0.3);
            \draw (B.east) -- (-0.2,-0.3);
            % Gate body: curved shape
            \draw (-0.2,0.6) .. controls (0,0.6) and (0.4,0.3) .. (0.6,0) .. controls (0.4,-0.3) and (0,-0.6) .. (-0.2,-0.6) -- cycle;
            % Output
            \node (Y) at (0.9,0) {$Y$};
            \draw (0.6,0) -- (Y.west);
        \end{tikzpicture}
    \end{center}
\end{definition}    

\begin{definition}[NOT Gate]
    A NOT gate outputs the inverse of the input. The truth table for a NOT gate is shown in Table \ref{tab:not_gate}.
    \\
    The logic function for a NOT gate with input $A$ can be expressed as:
    $$
        L(A) = \overline{A}
    $$
    The digital logic symbol for a NOT gate is shown below:
    \begin{center}
        \begin{tikzpicture}[scale=1]
            % Input node
            \node (A) at (-1,0) {$A$};
            % Wire to gate
            \draw (A.east) -- (-0.2,0);
            % Gate body: triangle with circle at output
            \draw (-0.2,0.5) -- (0.2,0) -- (-0.2,-0.5) -- cycle;
            \draw (0.2,0) circle (0.1);
            % Output
            \node (Y) at (0.6,0) {$Y$};
            \draw (0.3,0) -- (Y.west);
        \end{tikzpicture}
    \end{center}
\end{definition}


\subsection{Additional Logic Gates}
\begin{example}[XOR Operation]
    We have two switches; when both switches are in the same state (both open or both closed), the output is 0. When the switches are in different states (one open and one closed), the output is 1. The truth table for this operation is shown below:
    \begin{table}[h!]
        \centering
        \begin{tabular}{|c|c|c|}      
            \hline
            $x_1$ & $x_2$ & $L(x_1, x_2)$ \\
            \hline
            0 & 0 & 0 \\
            0 & 1 & 1 \\
            1 & 0 & 1 \\
            1 & 1 & 0 \\
            \hline
        \end{tabular}
        \caption{Truth Table for XOR Operation}
        \label{tab:xor_gate}
    \end{table}
    \\
    The logic function can be expressed as:
    $$
        L(x_1, x_2) = x_1 \oplus x_2 = \overline{x_1}x_2 + x_1\overline{x_2}
    $$
    where $\oplus$ denotes the XOR operation.
\end{example}

\begin{definition}[XOR Gate]
    An XOR gate outputs 1 if the inputs are different. The truth table for a 2-input XOR gate is shown in Table \ref{tab:xor_gate}.
    \\
    The logic function for an XOR gate with inputs $A$ and $B$ can be expressed as:
    $$
        L(A, B) = A \oplus B = \overline{A}B + A\overline{B}
    $$
    where $\oplus$ denotes the XOR operation.
    The digital logic symbol for an XOR gate is shown below:
    \begin{center}
        \begin{tikzpicture}[scale=1]
            % Input nodes
            \node (A) at (-1,0.3) {$A$};
            \node (B) at (-1,-0.3) {$B$};
            % Wires to gate
            \draw (A.east) -- (-0.2,0.3);
            \draw (B.east) -- (-0.2,-0.3);
            % Gate body: curved shape with extra curve on input side
            \draw (-0.4,0.6) .. controls (-0.2,0.6) and (0.2,0.3) .. (0.4,0) .. controls (0.2,-0.3) and (-0.2,-0.6) .. (-0.4,-0.6) -- cycle;
            \draw (-0.5,0.6) .. controls (-0.3,0.6) and (0.1,0.3) .. (0.3,0) .. controls (0.1,-0.3) and (-0.3,-0.6) .. (-0.5,-0.6);
            % Output
            \node (Y) at (0.9,0) {$Y$};
            \draw (0.4,0) -- (Y.west);
        \end{tikzpicture}
    \end{center}
\end{definition}


In addition, we have the following gates:
\begin{definition}[NAND Gate]
    A NAND gate outputs 0 only if all inputs are 1. The truth table for a 2-input NAND gate is as expected for the complement of AND.
    \\
    The logic function for a NAND gate with inputs $A$ and $B$ can be expressed as:
    $$
        L(A, B) = \overline{A \cdot B} = \overline{A} + \overline{B}
    $$
    The digital logic symbol for a NAND gate is shown below:
    \begin{center}
        \begin{tikzpicture}[scale=1]
            % Input nodes
            \node (A) at (-1,0.3) {$A$};
            \node (B) at (-1,-0.3) {$B$};
            % Wires to gate
            \draw (A.east) -- (-0.2,0.3);
            \draw (B.east) -- (-0.2,-0.3);
            % Gate body: rectangle on the left and semicircle on the right with circle at output
            \draw (-0.2,0.6) -- (-0.2,-0.6) -- (0.2,-0.6) arc (-90:90:0.6) -- cycle;
            \draw (0.2,0) circle (0.1);
            % Output
            \node (Y) at (0.9,0) {$Y$};
            \draw (0.6,0) -- (Y.west);
            \draw (0.2,0) -- (0.6,0);
        \end{tikzpicture}
    \end{center}
\end{definition}

\begin{definition}[NOR Gate]
    A NOR gate outputs 1 only if all inputs are 0. The truth table for a 2-input NOR gate is the dual of the OR gate.
    \\
    The logic function for a NOR gate with inputs $A$ and $B$ can be expressed as:
    $$
        L(A, B) = \overline{A + B}
    $$
    % A minimal symbolic sketch could be added similar to OR with an inversion bubble; omitted for brevity.
\end{definition}

\begin{shaded}
    \textbf{NAND and NOR Gates are Cheaper} NAND gates and NOR gates are cheaper than AND and OR gates because they require fewer transistors to implement. A 2-input NAND gate can be implemented using 4 transistors, while a 2-input AND gate requires 6 transistors (4 for the NAND gate and 2 for the NOT gate). The same applies to NOR and OR gates.

    \textbf{NAND and NOR Gates are Universal (Functionally Complete)} Additionally, NAND and NOR gates are universal gates, meaning that any logic function can be implemented using only NAND or NOR gates. 
    
    This makes them more versatile and cost-effective for building complex digital circuits.
\end{shaded}


% --- Algebra and minimization ---
\paragraph{Commonly Used Logic Operators} Below is a table summarizing the commonly used logic operators:
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        Operator & Symbol & Description \\
        \hline
    AND & $\cdot$ or adjacency & Outputs 1 if all inputs are 1 \\
    OR & $+$ & Outputs 1 if at least one input is 1 \\
    NOT & $\overline{x}$ or $x'$ or $\sim x$ & Outputs the logical negation of the input \\
    XOR & $\oplus$ & Outputs 1 if inputs are different \\
        NAND & $\overline{\cdot}$ & Outputs 0 if all inputs are 1 \\
        NOR & $\overline{+}$ & Outputs 0 if at least one input is 1 \\
        XNOR & $\overline{\oplus}$ & Outputs 1 if inputs are the same \\
        \hline
    \end{tabular}
    \caption{Commonly Used Logic Operators}
\end{table}

\subsection{Sum of Products (SOP) Form}
\begin{definition}[Literal]
    A literal is a variable or its negation. For example, $A$ and $\overline{A}$ are literals.  A literal can be either true or false, and it represents a single value in a logical expression.

\end{definition}

\begin{definition}[Product Term]
    A product term is a logical synonym for AND.
\end{definition}

\begin{definition}[Sum Term]
    A sum term is a logical synonym for OR.
\end{definition}

\begin{definition}[Sum of Products (SOP) Form]
    A logical expression is in sum of products (SOP) form if it is a sum of product terms. For example, the expression $AB + \overline{A}C + BC$ is in SOP form.
\end{definition}

\begin{definition}[Minterm]
    A product term that evaluates to one for exactly one row of the truth table is called a minterm.
\end{definition}
\begin{example}[Minterm]
    For a given truth table for $x_1, x_2, x_3$, the minterms are:
    \begin{table}[h!]
        \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            $x_1$ & $x_2$ & $x_3$ & Minterm \\
            \hline
            0 & 0 & 0 & $m_0 = \overline{x_1}\overline{x_2}\overline{x_3}$ \\
            0 & 0 & 1 & $m_1 = \overline{x_1}\overline{x_2}x_3$ \\
            0 & 1 & 0 & $m_2 = \overline{x_1}x_2\overline{x_3}$ \\
            0 & 1 & 1 & $m_3 = \overline{x_1}x_2x_3$ \\
            1 & 0 & 0 & $m_4 = x_1\overline{x_2}\overline{x_3}$ \\
            1 & 0 & 1 & $m_5 = x_1\overline{x_2}x_3$ \\
            1 & 1 & 0 & $m_6 = x_1x_2\overline{x_3}$ \\
            1 & 1 & 1 & $m_7 = x_1x_2x_3$ \\
            \hline
        \end{tabular}
        \caption{Minterms for 3 Variables}
        \label{tab:minterms}

    \end{table}
    \\
    Note that each minterm corresponds to a unique combination of input values that produces an output of 1. To create the minterm, you would try to make every literal one.

\end{example}

\begin{definition}[Canonical SOP Form]
    A logical expression is in canonical SOP form if it is a sum of minterms. 
\end{definition}

\subsection{Product of Sums (POS) Form}

\begin{definition}[Product of Sums (POS) Form]
    A logical expression is in product of sums (POS) form if it is a product of sum terms. For example, the expression $(A + B)(\overline{A} + C)(B + C)$ is in POS form.
\end{definition}


\begin{definition}[Maxterm]
    A sum term that evaluates to zero for exactly one row of the truth table is called a maxterm.
\end{definition}

\begin{example}[Maxterm]
    For a given truth table for $x_1, x_2, x_3$, the maxterms are:
    \begin{table}[h!]
        \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            $x_1$ & $x_2$ & $x_3$ & Maxterm \\
            \hline
            0 & 0 & 0 & $M_0 = (x_1 + x_2 + x_3)$ \\
            0 & 0 & 1 & $M_1 = (x_1 + x_2 + \overline{x_3})$ \\
            0 & 1 & 0 & $M_2 = (x_1 + \overline{x_2} + x_3)$ \\
            0 & 1 & 1 & $M_3 = (x_1 + \overline{x_2} + \overline{x_3})$ \\
            1 & 0 & 0 & $M_4 = (\overline{x_1} + x_2 + x_3)$ \\
            1 & 0 & 1 & $M_5 = (\overline{x_1} + x_2 + \overline{x_3})$ \\
            1 & 1 & 0 & $M_6 = (\overline{x_1} + \overline{x_2} + x_3)$ \\
            1 & 1 & 1 & $M_7 = (\overline{x_1} + \overline{x_2} + \overline{x_3})$ \\
            \hline
        \end{tabular}
        \caption{Maxterms for 3 Variables}
        \label{tab:maxterms}
    \end{table}
    \\
    Note that each maxterm corresponds to a unique combination of input values that produces an output of 0. To create the maxterm, you would try to make every literal zero.
\end{example}

\begin{definition}[Canonical POS Form]
    A logical expression is in canonical POS form if it is a product of maxterms.
\end{definition}

\begin{theorem}[Converting between Canonical Forms]
    Any logical expression can be converted from canonical SOP form to canonical POS form and vice versa. For $i \in \{0, 1, \ldots, 2^n - 1\}$ and $S \subseteq \{0, 1, \ldots, 2^n - 1\}$, we have:
    \[
        f(x_1, x_2, \ldots, x_n) = \sum_{i \in S} m_i = \prod_{i \notin S} M_i
    \]
\end{theorem}
\begin{example}
    We have the following converison:
    $$
        f(x_1, x_2, x_3) = m_1 + m_3 + m_5 + m_7 = M_0 M_2 M_4 M_6
    $$
\end{example}

\subsection{Boolean Algebra and Logic Minimization}
\begin{definition}[Boolean Algebra]
    Boolean algebra is a branch of algebra that deals with binary variables and logical operations. It is a effective means to describe logic circuits with a set of rules derived from the axioms of Boolean algebra.
\end{definition}

\begin{definition}[Axioms of Boolean Algebra]
    The axioms of Boolean algebra are a set of fundamental rules that govern the behavior of binary variables and logical operations. The number stems consist only of the set $\{0, 1\}$, with the following axioms:
    \begin{itemize}
        \item $0 \cdot 0 = 0$
        \item $1 \cdot 1 = 1$
        \item $0 \cdot A = 0 \cdot 1 = 1 \cdot 0 = 0$ for any $A$
        \item if $x=0$ then $\overline{x} = 1$
    \end{itemize}

    \textbf{Dual Form} We can also derive the following logical equivalences from the axioms:
    \begin{itemize}
        \item $A + 0 = A$
        \item $A + 1 = 1$
        \item $0 + 1 = 1 + 0 = 1$
        \item $A + \overline{A} = 1$
    \end{itemize}

    where $1$ is the multiplicative identity and $0$ is the additive identity.
\end{definition}

\paragraph{Rules derived from the Axioms of Boolean Algebra} The following rules can be derived from the axioms of Boolean algebra:
\begin{theorem}
\begin{itemize}
    \item $x \cdot 0 = 0$ (Annihilation)
    \item $x \cdot 1 = 1 \cdot x = x$ (Identity)
    \item $x \cdot \overline{x} = 0$ (Complementation)
    \item $x \cdot x = x$ (Idempotent)
    \item $x + 0 = 0 + x = x$ (Identity)
    \item $x + 1 = 1 + x = 1$ (Annihilation)
    \item $x + \overline{x} = 1$ (Complementation)
\end{itemize}
\end{theorem}

\begin{theorem}
The following identities can be derived from the axioms of Boolean algebra:
\begin{itemize}
    \item Commutative Laws:
    \begin{itemize}
        \item $A + B = B + A$
        \item $A \cdot B = B \cdot A$
    \end{itemize}
    \item Associative Laws:
    \begin{itemize}
        \item $A + (B + C) = (A + B) + C$
        \item $A \cdot (B \cdot C) = (A \cdot B) \cdot C$
    \end{itemize}
    \item Distributive Laws:
    \begin{itemize}
        \item $A \cdot (B + C) = A \cdot B + A \cdot C$
        \item $A + (B \cdot C) = (A + B) \cdot (A + C)$
    \end{itemize}
\end{itemize}
\end{theorem}
\begin{proof}
    By perfect induction. We can exhaustively check all possible values of $A$, $B$, and $C$ (0 or 1) to verify that both sides of each identity yield the same result.
\end{proof}

\begin{theorem}[Covering Theorem]
     The following is true:
    $$    
    x + xy = x
    $$
    and its dual:
    $$
    x(x + y) = x
    $$
\end{theorem}

\begin{theorem}[Combining Theorem]
    The following is true:
    $$
    xy + x\overline{y} = x
    $$
    and its dual:
    $$
    (x + y)(x + \overline{y}) = x
    $$
    
\end{theorem}

\begin{theorem}[De Morgan's Theorem]
    The following is true:
    $$
    \overline{xy} = \overline{x} + \overline{y}
    $$
    and its dual:
    $$
    \overline{x + y} = \overline{x} \cdot \overline{y}
    $$
\end{theorem}
\begin{proof}
    By direct proof. We have:
    \begin{align*}
        \overline{xy} &= \overline{x}\overline{y} + \overline{x}y + x\overline{y} \quad (\text{In Canonical SOP Form}) \\
        &= \overline{x}\overline{y} + \overline{x}y + x\overline{y} + x\overline{y} \quad (\text{Adding } x\overline{y} \text{ using $x + x = x$}) \\
        &= \overline{x}(\overline{y} + y) + \overline{y}(x + \overline{x}) \quad (\text{Using Distributive Law}) \\
        &= \overline{x} \cdot 1 + \overline{y} \cdot 1 \quad (\text{Using Complementation}) \\
        &= \overline{x} + \overline{y} \quad (\text{Using Identity})
    \end{align*}
\end{proof}

\begin{theorem}[Absorption / Redundancy Theorem]
    The following is true:
    $$
    x + \overline{x}y = x + y
    $$
    and its dual:
    $$
    x(\overline{x} + y) = xy
    $$
\end{theorem}
\begin{proof}
    By direct proof. We have:
    \begin{align*}
        x + \overline{x}y &= x + \overline{x}y + xy \quad (\text{Adding } xy \text{ using } x + xy = x) \\
        &= x(1 + y) + \overline{x}y \quad (\text{Using Distributive Law}) \\
        &= x \cdot 1 + \overline{x}y \quad (\text{Using Identity}) \\
        &= x + y \quad (\text{Using Combining Theorem})
    \end{align*}
\end{proof}

\paragraph{Summary of Important Theorems} The following table summarizes the important theorems/laws in Boolean algebra:
\begin{table}[h!]
    \centering
    \caption{Summary of Important Theorems/Laws in Boolean Algebra (original form and dual form)}
    \label{tab:boolean_algebra_summary}
    \begin{tabular}{|l|c|c|}
         \hline
            \textbf{Law / Theorem} & \textbf{Original Form(s)} & \textbf{Dual Form(s)} \\ \hline
            Commutative Law & $A + B = B + A$ & $A \cdot B = B \cdot A$ \\ \hline
            Associative Law & $A + (B + C) = (A + B) + C$ & $A \cdot (B \cdot C) = (A \cdot B) \cdot C$ \\ \hline
            Distributive Law & $A \cdot (B + C) = A \cdot B + A \cdot C$ & $A + (B \cdot C) = (A + B) \cdot (A + C)$ \\ \hline
            Identity Law & $A + 0 = A$ & $A \cdot 1 = A$ \\ \hline
            Null Law & $A + 1 = 1$ & $A \cdot 0 = 0$ \\ \hline
            Idempotent Law & $A + A = A$ & $A \cdot A = A$ \\ \hline
            Complement Law & $A + \overline{A} = 1$ & $A \cdot \overline{A} = 0$ \\ \hline
            Double Negation Law & $\overline{\overline{A}} = A$ & - \\ \hline
            De Morgan's Theorem & $\overline{A \cdot B} = \overline{A} + \overline{B}$ & $\overline{A + B} = \overline{A} \cdot \overline{B}$ \\ \hline
            Absorption / Redundancy Theorem & $A + \overline{A}B = A + B$ & $A(\overline{A} + B) = AB$ \\ \hline
            Combining Theorem & $AB + A\overline{B} = A$ & $(A + B)(A + \overline{B}) = A$ \\ \hline
            Covering Theorem & $A + AB = A$ & $A(A + B) = A$ \\ \hline  
    \end{tabular}
\end{table}
\newpage
\begin{shaded}
    \paragraph{Logic Minimization} The goal of logic minimization is to reduce the number of logic gates and inputs in a digital circuit while maintaining its functionality. This is important because it can lead to cost savings, improved performance, and reduced power consumption. Logic minimization can be achieved through various techniques, including Boolean algebra simplification, Karnaugh maps, and the Quine-McCluskey algorithm.
\end{shaded}

\begin{theorem}[Nand as SOP]
    And SOP circuit can be implemented using only NAND gates.
\end{theorem}

\begin{theorem}[Nor as POS]
    A POS circuit can be implemented using only NOR gates.
\end{theorem}

\begin{example}[Gumball Fact]
    Consider three sensors $s_0, s_1, s_2$ that detect defects in Gumballs. Those sensors are normally 0, but would be 1 if a defect is detected as follows:
    $$
        \begin{cases}
            s_0 = 1 & \text{if the Gumball is too small} \\
            s_1 = 1 & \text{if the Gumball is too big} \\
            s_2 = 1 & \text{if the Gumball is too light}
        \end{cases}
    $$
    We are to design a circuit that would output 1 if the Gumball is either too large or too small and too light. We can express canonical SOP form as:
    \begin{align*}
        L(s_0, s_1, s_2) &= m_3 + m_4 + m_5 + m_6 + m_7 \\ 
        &= \overline{s_0}s_1s_2 + s_2\overline{s_0}\overline{s_2} + s_0\overline{s_1}s_2 + s_0s_1\overline{s_2} + s_0s_1s_2 \\
        \intertext{Using the Combining Theorem}
        &= \overline{s_0}s_1s_2 + s_2\overline{s_0}\overline{s_2} + s_0s_2 + s_0s_1 \\
        \intertext{Using the Absorption Theorem}
        &= s_2\overline{s_0} + s_0s_2 + s_0s_1 \\
        \intertext{Using the Covering Theorem}
        &= s_2 + s_0s_1 
    \end{align*}
\end{example}

\begin{example}
    \textit{Derive a minimal POS expression for $f(x_1, x_2, x_3 = \prod M(0, 2, 4)$}
    \\
    We have:
    \begin{align*}
        f(x_1, x_2, x_3) &= M_0 M_2 M_4 \\
        &= (x_1 + x_2 + x_3)(x_1 + \overline{x_2} + x_3)(\overline{x_1} + x_2 + x_3) \\
    \intertext{Recognizing the combining theorem $(x+y)(x+\overline{y}) = x$}
        &= (x_1 + x_3)(x_2 + x_3)(\overline{x_1} + x_3) \\
        &= (x_1 + x_3)(x_2 + \overline{x_1} + x_3) \\
        &= (x_1 + x_3)(x_2 + x_3)
    \end{align*}   
\end{example}

\begin{theorem}[Transporting POS to SOP]
    A POS circuit can be implemented using only NAND gates. This is achieved by applying De Morgan's Theorem and the properties of NAND gates. We can use the trick $f = \overline{\overline{f}}$ to convert the POS expression into a form that can be implemented with NAND gates.
\end{theorem}
\begin{theorem}[Transporting SOP to POS]
    An SOP circuit can be implemented using only NOR gates. This is achieved by applying De Morgan's Theorem and the properties of NOR gates. We can use the trick $f = \overline{\overline{f}}$ to convert the SOP expression into a form that can be implemented with NOR gates.
\end{theorem}

\begin{example}
    \textit{Implement the function $f(x_1, x_2, x_3) = \sum m(1, 3, 5, 7)$ using only NAND gates.}
    \\
    We have:
    \begin{align*}
        f(x_1, x_2, x_3) &= m_1 + m_3 + m_5 + m_7 \\
        &= \overline{x_1}\overline{x_2}x_3 + \overline{x_1}x_2x_3 + x_1\overline{x_2}x_3 + x_1x_2x_3 \\
        &= x_3(\overline{x_1}\overline{x_2} + \overline{x_1}x_2 + x_1\overline{x_2} + x_1x_2) \\
        &= x_3(x_1 + x_2) \quad (\text{Using Combining Theorem}) \\
        &= \overline{\overline{x_3(x_1 + x_2)}} \quad (\text{Using } f = \overline{\overline{f}}) \\
        &= \overline{\overline{x_3} + \overline{x_1 + x_2}} \quad (\text{Using De Morgan's Theorem}) \\
        &= \overline{\overline{x_3} + (\overline{x_1} \cdot \overline{x_2})} \quad (\text{Using De Morgan's Theorem}) 
    \end{align*}    
\end{example}

% ===================== PART B: DESIGN METHODS AND HDL =====================
\section{Combinational Logic Circuits}

\begin{definition}[Combinational Logic Circuit]
    A combinational logic circuit is a digital circuit that implements a specific logic function using a combination of logic gates. The output of a combinational logic circuit depends only on the current inputs and not on any previous inputs or states. 
\end{definition}
\begin{definition}{Hardware Description Language (HDL)}
    A hardware description language (HDL) is a specialized programming language used to describe the structure, behavior, and operation of electronic circuits and systems. HDLs are used in the design and verification of digital systems, including integrated circuits (ICs) and field-programmable gate arrays (FPGAs). The two most commonly used HDLs are VHDL (VHSIC Hardware Description Language) and Verilog.
\end{definition}
\subsection{Introduction of Verilog}


\begin{definition}[Module]
    A module is a self-contained block of hardware that has inputs and outputs and an internal implementation (behavioral or structural). Modules are the unit of hierarchy in Verilog.
\end{definition}

\begin{example}[Module Block]
    A module block in Verilog is defined using the `module` keyword, followed by the module name and a list of input and output ports. For example:
    \begin{verbatim}
    module basic_logic(input logic a, b,
                       output logic w, x, y, z);
        assign w = a & b; // AND gate
        assign x = a | b; // OR gate
        assign y = ~a;    // NOT gate
        assign z = a ^ b; // XOR gate
    endmodule
    \end{verbatim}

    \textbf{Keywords} The keywords used in the module block are:
    \begin{itemize}
        \item \verb|assign|: Used to define continuous assignments for combinational logic.
        \item \verb|logic|: A type of variable that can hold binary values (0 or 1).
    \end{itemize}
\end{example}

\begin{definition}[Continuous Assignment]
    A continuous assignment is used to model combinational logic in Verilog. It is defined using the \verb|assign| keyword, followed by the output signal, the assignment operator `=`, and the logic expression. Continuous assignments are evaluated whenever any of the input signals change. That is, the output is considered instantaneously updated when the input changes (ignoring propagation delay).
\end{definition}

\begin{example}[2-1 Multiplexers (Mux)]
    \textit{Design a circuit that controls a light $f$ based on either two switches $x$ and $y$. The switch that control the light is determined by a control signal $s$. If $s = 0$, the light is controlled by switch $x$. If $s = 1$, the light is controlled by switch $y$.}
    \\
    We have the following truth table:

    \begin{table}[h!]
        \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            $s$ & $x$ & $y$ & $f$ \\
            \hline
            0 & 0 & 0 & 0 \\
            0 & 0 & 1 & 0 \\
            0 & 1 & 0 & 1 \\
            0 & 1 & 1 & 1 \\
            1 & 0 & 0 & 0 \\
            1 & 0 & 1 & 1 \\
            1 & 1 & 0 & 0 \\
            1 & 1 & 1 & 1 \\
            \hline
        \end{tabular}
        \caption{Truth Table for Mux}
        \label{tab:mux_truth_table}
    \end{table}
    
    From the truth table, we can derive the following canonical SOP expression:
    \begin{align*}
        f(s, x, y) &= m_2 + m_3 + m_5 + m_7 \\
        &= \overline{s}x\overline{y} + \overline{s}xy + s\overline{x}y + sxy \\
        &= \overline{s}x(\overline{y} + y) + sy(\overline{x} + x) \quad (\text{Using Distributive Law}) \\
        &= \overline{s}x \cdot 1 + sy \cdot 1 \quad (\text{Using Complementation}) \\
        &= \overline{s}x + sy \quad (\text{Using Identity})
    \end{align*}

    The verilog implementation is as follows:
    \begin{verbatim}
    module mux2to1(input logic x, y, s,
                   output logic f);
        assign f = (~s & x) | (s & y);
    endmodule
    \end{verbatim}
\end{example}

\paragraph{The diagram of a Mux} is a trapezoid shown below:
\begin{center}
    \begin{tikzpicture}[scale=1]
        % Input nodes
        \node (x) at (-2,0.5) {$x$};
        \node (y) at (-2,-0.5) {$y$};
        \node (s) at (-0.5,1.5) {$s$}; 
        % Wires to gate
        \draw (x.east) -- (-1,0.5);
        \draw (y.east) -- (-1,-0.5);
        \draw (s.south) -- (-0.5,0.75);
        % Gate body: trapezoid
        \draw (-1,1) -- (0,0.5) -- (0,-0.5) -- (-1,-1) -- cycle;
        % Output
        \node (f) at (1,0) {$f$};

        \node (0) at (-0.6,0.3) {0};
        \node (1) at (-0.6,-0.2) {1};
        \draw (0,0) -- (f.west);
    \end{tikzpicture}
\end{center}

\paragraph{4-1 Multiplexer (Mux)} A 4-1 Mux has 4 data inputs ($d_0, d_1, d_2, d_3$). The select signal would have two bit ($s_0, s_1$) to select one of the four data inputs to be outputted. In general, this is call a multibit signal, a.k.a a bus.
\begin{definition}
    
\end{definition}



% ===================== PART C: SEQUENTIAL LOGIC =====================
\section{Digital Storage Elements}
% Flip-flops, latches, registers (to be expanded)

\section{Finite State Machines (FSM)}
% FSM modeling, state diagrams, and Verilog implementation (to be expanded)

\chapter{Computer Organization and Assembly Language}
\begin{shaded}
\textbf{What is Assembly Language?} We know that we can run C/C++ on any computer (Machine Agnostic), but how does the computer understand C/C++? The answer is the compiler that parse it to assembly through:

\begin{enumerate}
    \item \textbf{Front-end Parser:} The front-end parser would parse the C/C++ code into an intermediate representation (IR), which is a low-level representation of the code that is easier to optimize. The front-end parser would also perform optimizations on the IR, such as loop unrolling, inlining, and dead code elimination.
    \item \textbf{Back-end Parser:} The back-end parser would take the optimized IR and generate assembly code for a specific architectures.
\end{enumerate}
\end{shaded}
The assembly code is then assembled into machine code, which is a series of 0s and 1s that the computer can understand. The assembly would be specific to the architecture of the computer (machine dependent), which is why we have different assembly languages for different architectures (e.g., x86, RISC-V, ARM).
\section{Computer Organization}

\section{Assembly Language}
\end{document}

